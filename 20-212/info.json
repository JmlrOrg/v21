{
    "abstract": "Reinforcement learning (RL) is a popular paradigm for addressing sequential decision tasks in which the agent has only limited environmental feedback. Despite many advances over the past three decades, learning in many domains still requires a large amount of interaction with the environment, which can be prohibitively expensive in realistic scenarios. To address this problem, transfer learning has been applied to reinforcement learning such that experience gained in one task can be leveraged when starting to learn the next, harder task. More recently, several lines of research have explored how tasks, or data samples themselves, can be sequenced into a curriculum for the purpose of learning a problem that may otherwise be too difficult to learn from scratch. In this article, we present a framework for curriculum learning (CL) in reinforcement learning, and use it to survey and classify existing CL methods in terms of their assumptions, capabilities, and goals. Finally, we use our framework to find open problems and suggest directions for future RL curriculum learning research.",
    "authors": [
        "Sanmit Narvekar",
        "Bei Peng",
        "Matteo Leonetti",
        "Jivko Sinapov",
        "Matthew E. Taylor",
        "Peter Stone"
    ],
    "emails": [
        "sanmit@cs.utexas.edu",
        "bei.peng@cs.ox.ac.uk",
        "m.leonetti@leeds.ac.uk",
        "jivko.sinapov@tufts.edu",
        "matthew.e.taylor@ualberta.ca",
        "pstone@cs.utexas.edu"
    ],
    "id": "20-212",
    "issue": 181,
    "pages": [
        1,
        50
    ],
    "title": "Curriculum Learning for Reinforcement Learning Domains: A Framework and Survey",
    "volume": 21,
    "year": 2020
}